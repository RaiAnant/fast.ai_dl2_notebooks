{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl2_fastai_lec9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaiAnant/fast.ai_dl2_notebooks/blob/master/dl2_fastai_lec9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUKCK8DxNWHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import operator\n",
        "from torch.nn import init\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\n",
        "\n",
        "\n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "\n",
        "def test_near(a,b): test(a,b,near)  \n",
        "  \n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s\n",
        "\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
        "  \n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjZ3pyglN3wd",
        "colab_type": "code",
        "outputId": "2256f0d8-9172-4ac1-bb5f-f865e5de8d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cixl9tCxNu4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BylmiT_bN0Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8PmstIeXe3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlBXKvYuXjro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfYdWsNhXoNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuoB3PFXsUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kugE0F2YEGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeZxLOGXt54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim = True))).log() # why -1 and why keepdim?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKYjaO6zYyjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = torch.randn(5,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y75enF2Y3FC",
        "colab_type": "code",
        "outputId": "93d62651-a1f9-4362-f99a-47b13cdfd9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "test,test.sum(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.2886,  1.1939,  0.1207,  0.2071,  0.8255,  0.4038, -0.9863, -1.7424,\n",
              "           1.3512,  0.9791],\n",
              "         [-0.0943, -0.5070,  0.4600,  0.6857, -0.0174, -0.0500, -0.0726, -0.9171,\n",
              "           0.9473, -0.9546],\n",
              "         [ 0.2471,  0.2655,  0.8119, -0.3634,  0.8797, -0.0829,  0.2561,  1.0865,\n",
              "           2.3686, -1.7423],\n",
              "         [ 0.1714, -0.0833,  1.6647, -2.8112, -0.0351, -1.4104, -0.2560,  0.3811,\n",
              "          -1.1496, -1.5089],\n",
              "         [-0.4461, -1.1441, -0.5706, -0.9626,  0.1693,  1.2911, -0.6815,  0.9491,\n",
              "           0.3498,  1.0629]]),\n",
              " tensor([ 1.1667, -0.2749,  2.4866, -3.2445,  1.8222,  0.1517, -1.7403, -0.2428,\n",
              "          3.8673, -2.1639]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AobgzTLdY-Qs",
        "colab_type": "code",
        "outputId": "b0948d5a-4e66-494e-83a7-e6e93dc5e8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test.sum(0,keepdim = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1667, -0.2749,  2.4866, -3.2445,  1.8222,  0.1517, -1.7403, -0.2428,\n",
              "          3.8673, -2.1639]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfly2gXIZRpL",
        "colab_type": "code",
        "outputId": "d1e3077d-0115-4da7-f155-53727f4d4e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "test.sum(-1),test.sum(-1,keepdim = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3.6412, -0.5200,  3.7267, -5.0373,  0.0173]), tensor([[ 3.6412],\n",
              "         [-0.5200],\n",
              "         [ 3.7267],\n",
              "         [-5.0373],\n",
              "         [ 0.0173]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-1AN6OkZYBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6fvB1ufZv_v",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWJaMXa_ZvOn",
        "colab_type": "code",
        "outputId": "97430090-c26a-45bb-ed56-ece1595fedbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvEfPLmsblP",
        "colab_type": "code",
        "outputId": "de62f8d9-b63a-4cd5-8ecf-8555f83dc0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sm_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9TE4nlBwEDR",
        "colab_type": "text"
      },
      "source": [
        "Indexing ways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTCCbuIBvkZy",
        "colab_type": "code",
        "outputId": "09e9fd1c-f5f9-490d-ee5c-b3c9b0a1e53d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "sm_pred[[1,2,3]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4212, -2.3529, -2.2624, -2.2718, -2.3280, -2.3835, -2.3333, -2.2698,\n",
              "         -2.2333, -2.1921],\n",
              "        [-2.4001, -2.3418, -2.3694, -2.2427, -2.3305, -2.2900, -2.3227, -2.3187,\n",
              "         -2.2523, -2.1774],\n",
              "        [-2.4282, -2.3261, -2.3564, -2.2675, -2.3213, -2.3827, -2.2706, -2.2555,\n",
              "         -2.2141, -2.2253]], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sN11oTRxPyT",
        "colab_type": "code",
        "outputId": "af74d272-54b3-4a2f-85da-2be2aa92af02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4152, -2.4338, -2.2655],\n",
              "        [-2.3835, -2.4212, -2.3280],\n",
              "        [-2.2900, -2.4001, -2.3305],\n",
              "        ...,\n",
              "        [-2.3756, -2.4432, -2.3077],\n",
              "        [-2.4164, -2.5632, -2.3472],\n",
              "        [-2.3579, -2.4393, -2.2765]], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAkqKTqTwBZR",
        "colab_type": "code",
        "outputId": "a0be923d-9f0b-43d3-ed6b-2f22b8ff7f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sm_pred[[0,1,2],[5, 0, 4]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.4152, -2.4212, -2.3305], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwRBkuNzwOp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]),target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdgJnTOAxFQl",
        "colab_type": "code",
        "outputId": "73edcbbd-cb67-4733-c00c-75ee46af0386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2992, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPa0OkoVyBhZ",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "737QMBWCx8qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR5DjTD1yIWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4lUz7SayuVe",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWWFnrsyLZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7OwMWv82iDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAL6uLft2nmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7VNvjG2t3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4SlrK3c2xcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch's implementation.\n",
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM3utHEI22Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy\n",
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piDX1oHq3Eqk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "1.get the output of the model on a batch of inputs\n",
        "\n",
        "2.compare the output to the labels we have and compute a loss\n",
        "\n",
        "3.calculate the gradients of the loss with respect to every parameter of the model\n",
        "\n",
        "4.update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0jpVha3CJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOoS8lu3zzb",
        "colab_type": "code",
        "outputId": "d192227b-5a4a-420c-e9f8-08b518b1fe4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "temp = tensor([[0,1,0],[1,0,0],[1,0,0]]).float()\n",
        "temp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1BFUSnJ45kv",
        "colab_type": "code",
        "outputId": "29a88656-4666-4926-9163-a7724401e545",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.argmax(temp,dim=1),torch.argmax(temp,dim=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 0, 0]), tensor([2, 0, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtbYr1o3X5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb): return (torch.argmax(out,dim=1)==yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my07FKMQ5C1-",
        "colab_type": "code",
        "outputId": "cbcc0200-f923-43e4-deda-3fa98aea48bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bs = 64\n",
        "\n",
        "xb = x_train[:bs]\n",
        "preds = model(xb)\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0859, -0.0278, -0.0480,  0.0919,  0.0823, -0.0673, -0.0209,  0.0993,\n",
              "          0.1306,  0.2466], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpAup36Q5lM0",
        "colab_type": "code",
        "outputId": "8c0fec73-2a1b-4d72-b019-a5a3f477e8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.2916, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMhIEx5B7QHw",
        "colab_type": "code",
        "outputId": "0ec2af44-36c1-4d72-a59f-8654034c4ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1406)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4hZ9z0H7UcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.1 \n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAJURLbf7v4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = x_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHh6wWVOKHsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R48uyBdh7htX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch in range((n-1)//bs +1):\n",
        "    \n",
        "    x_batch = x_train[batch*bs:(batch+1)*bs]\n",
        "    y_batch = y_train[batch*bs:(batch+1)*bs]\n",
        "    \n",
        "    preds = model(x_batch)\n",
        "    \n",
        "    loss = loss_func(preds,y_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad*lr\n",
        "          l.bias -= l.bias.grad*lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umDCBQQZE-mC",
        "colab_type": "code",
        "outputId": "d5a2ba39-42a7-4d7b-e289-14f5e72ba730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3147, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duhixw1hUhFv",
        "colab_type": "text"
      },
      "source": [
        "Using parameters and optim\n",
        "\n",
        "Parameters\n",
        "\n",
        "Use nn.Module.__setattr__ and move relu to functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9F3S4QFKgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyloIqjATJOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl97hFDyUxVA",
        "colab_type": "code",
        "outputId": "f7f17822-23bc-4395-a0a0-3732866383fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIMtNCl6U5fH",
        "colab_type": "code",
        "outputId": "d31f74e6-1a00-4a36-bf6d-e3d37cb0a1f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcKKrtbWVKJ5",
        "colab_type": "code",
        "outputId": "1cbde4d9-d364-4f0e-e961-741b98f1be64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naiMuzMWVO3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD6TOHC6aHmQ",
        "colab_type": "code",
        "outputId": "ac7a5a20-80e6-4b25-b6cb-77103d5794c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3180, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ7WFG6laWRb",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84eenkEZaLSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        self.n = 3\n",
        "        \n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\") and hasattr(v,'parameters'): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "        \n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters(): yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mgsTewnaerl",
        "colab_type": "code",
        "outputId": "4e8246d6-b873-44bb-a56a-5dfd82e0a32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "mdl = DummyModule(m,nh,10)\n",
        "mdl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXNJQCa4ZP",
        "colab_type": "code",
        "outputId": "d48cc4fb-8c9c-4729-8f2a-11a43043d92f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANDcit_NehxT",
        "colab_type": "text"
      },
      "source": [
        "**Registering modules**\n",
        "\n",
        "We can use the original layers approach, but we have to register the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0RSQvLFbAWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm_eV-wPcDHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0ii6xJev8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ6UoWC1e0E2",
        "colab_type": "code",
        "outputId": "207792f0-38e7-477b-abbf-dbe35e1465be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8X3CbG7fIF-",
        "colab_type": "text"
      },
      "source": [
        "**nn.ModuleList**\n",
        "\n",
        "nn.ModuleList does this for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6t3-sVPe1tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHuXCPpifPdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6rWTfDfRP3",
        "colab_type": "code",
        "outputId": "66ac6e93-75c7-4891-9276-4d19df0db29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPPz2mhfS1B",
        "colab_type": "code",
        "outputId": "e92a5a9f-1056-4229-b525-96adef8b77f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3305, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8HuspGflrO",
        "colab_type": "text"
      },
      "source": [
        "**nn.Sequential**\n",
        "\n",
        "nn.Sequential is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPUdXgKSfVXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpUMMEbhiOdS",
        "colab_type": "code",
        "outputId": "51de7f80-8dd1-4921-dbdd-0f80e5a1b4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3046, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md3eV2aLiQbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-5gxUziS1W",
        "colab_type": "code",
        "outputId": "5106d74d-4cf0-49b6-e2fe-afae3ac150e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CYQSFwtilCU",
        "colab_type": "text"
      },
      "source": [
        "**optim**\n",
        "\n",
        "Let's replace our previous manually coded optimization step\n",
        ":\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "\n",
        "    \n",
        "and instead use just:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyZR68_MijxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "  \n",
        "  def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "    \n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params: p -= p.grad*lr\n",
        "        \n",
        "  def zero_grad(self):\n",
        "    for p in self.params: p.grad.data.zero_()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL6OeNsgjjKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGivvEhHjmCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkrOfewsjoIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4O1DSilD7_",
        "colab_type": "code",
        "outputId": "a5df8eb9-c6f2-4cdc-b114-0007b5752b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1722, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "andZAjaHlM72",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmH_-L2JlGv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiIAbOh5lV0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CziWLb_XlYlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB1cYFDKrSr2",
        "colab_type": "code",
        "outputId": "96cfbfef-ffaa-4f0f-89e4-603e049e1bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3040, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYdlUxFrVdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iskbinMercoi",
        "colab_type": "code",
        "outputId": "1ccf239c-8856-4236-a68c-3196732c8b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1612, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F715hr6frfnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-9d-jZarj-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self,i): return self.x[i],self.y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyB_uDJPr4uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train,y_train), Dataset(x_valid,y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEUtkF7ssIx",
        "colab_type": "code",
        "outputId": "ef704527-09e7-44a3-e103-1527bc3cda9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGTjmeMSs8CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Y3QdeEs_wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B52JG0ktUD7",
        "colab_type": "code",
        "outputId": "d46cd3ad-cce9-468c-a63f-e4e2e726894b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1593, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKhA_HrmucNv",
        "colab_type": "text"
      },
      "source": [
        "**DataLoader**\n",
        "\n",
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "```\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "\n",
        "```\n",
        "for xb,yb in train_dl:\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdYmexnutZmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs): self.ds, self.bs = ds,bs\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs] # note here yield is used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBgkn9YfvzD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TRdEiM4v-pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY47_Y_hwA-4",
        "colab_type": "code",
        "outputId": "badf5215-a0eb-44dd-b8c9-68c543314c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWxGsrprwMH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1wXWEfpwqPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOwm0y4Gwr_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjH_wVquws8A",
        "colab_type": "code",
        "outputId": "8ede73ec-be70-4792-db1f-70dd50286593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2847, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31zJUfXZyi5D",
        "colab_type": "text"
      },
      "source": [
        "**Random sampling**\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP5fyO3SwwzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, bs, shuffle=False):\n",
        "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNdGn3CxyOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43n3gwrixz-W",
        "colab_type": "code",
        "outputId": "addf8a2d-73b2-4596-ad3c-acaf04debdb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fv-VikxyIxo",
        "colab_type": "code",
        "outputId": "ce053bf2-3aa1-4756-b4e2-18d505bf6bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([8, 1, 0]), tensor([4, 5, 2]), tensor([6, 9, 7]), tensor([3])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nd-5nLDyO2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)\n",
        "  \n",
        "class DataLoader():\n",
        "    def __init__(self, ds, sampler, collate_fn=collate):\n",
        "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvvU2YpHyW3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMhmI-1WygbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLiaH4cy22a",
        "colab_type": "code",
        "outputId": "cfe634f7-3b77-442a-d1c1-8f63f7303ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EnONtBI3kvX",
        "colab_type": "code",
        "outputId": "78a18c32-d269-445c-821c-2580e0a42e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7654P23nm9",
        "colab_type": "code",
        "outputId": "8cbbedec-a98b-47ea-ebe6-a9225ad0a523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aBdLj6z3szx",
        "colab_type": "code",
        "outputId": "19c3a739-864a-4b19-ddf8-f71f4972086e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2848, grad_fn=<NllLossBackward>), tensor(0.8906))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQgDoLiQ4Nui",
        "colab_type": "text"
      },
      "source": [
        "**PyTorch DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l_Js-wW3xRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMwt9YbJ4Tnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGaqYjH4X72",
        "colab_type": "code",
        "outputId": "3b980f5d-6a40-4f4c-e95d-80110b33fe2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2787, grad_fn=<NllLossBackward>), tensor(0.8906))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVmBiX7265SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DataLoader??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMJPWXTo4aGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6JYlHP_7cSH",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXs-_RrB4d3v",
        "colab_type": "code",
        "outputId": "269224d5-cc65-4fc1-8cff-034547a1bc58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2600, grad_fn=<NllLossBackward>), tensor(0.9531))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0masRS8S7kRd",
        "colab_type": "text"
      },
      "source": [
        "Note that PyTorch's DataLoader, if you pass num_workers, will use multiple threads to call your Dataset.\n",
        "\n",
        "\n",
        "\n",
        "**Validation**\n",
        "\n",
        "You always should also have a validation set, in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NY_fgiD7Gpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          # we calculate loss and accuracy on valid set which is displayed as metric after each epoch\n",
        "          tot_loss, tot_acc = 0.,0.\n",
        "          for xb, yb in valid_dl:  \n",
        "            pred = model(xb)\n",
        "            tot_loss += loss_func(pred, yb)\n",
        "            tot_acc += accuracy(pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "        \n",
        "    return tot_loss/nv, tot_acc/nv\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqcZwMYo-Yep",
        "colab_type": "text"
      },
      "source": [
        "Question: Are these validation results correct if batch size varies?\n",
        "\n",
        "get_dls returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzjJu0sv8A_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8_KHoGn8EN1",
        "colab_type": "code",
        "outputId": "ed9efa9f-565f-43b3-830e-757a2edcf1c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.3979) tensor(0.8767)\n",
            "1 tensor(0.2186) tensor(0.9393)\n",
            "2 tensor(0.1743) tensor(0.9520)\n",
            "3 tensor(0.1569) tensor(0.9557)\n",
            "4 tensor(0.1427) tensor(0.9602)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1nRVOXU-vn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8WTIKYz-5oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}