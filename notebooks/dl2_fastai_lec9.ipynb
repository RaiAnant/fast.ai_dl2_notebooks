{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl2_fastai_lec9.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUKCK8DxNWHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import operator\n",
        "from torch.nn import init\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'\n",
        "\n",
        "\n",
        "def test(a,b,cmp,cname=None):\n",
        "    if cname is None: cname=cmp.__name__\n",
        "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
        "\n",
        "def test_eq(a,b): test(a,b,operator.eq,'==')\n",
        "\n",
        "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
        "\n",
        "def test_near(a,b): test(a,b,near)  \n",
        "  \n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s\n",
        "\n",
        "def test_near_zero(a,tol=1e-3): assert a.abs()<tol, f\"Near zero: {a}\"\n",
        "  \n",
        "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjZ3pyglN3wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cixl9tCxNu4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BylmiT_bN0Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8PmstIeXe3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n,m = x_train.shape\n",
        "c = y_train.max()+1\n",
        "nh = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlBXKvYuXjro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfYdWsNhXoNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuoB3PFXsUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kugE0F2YEGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "F??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeZxLOGXt54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return (x.exp()/(x.exp().sum(-1,keepdim = True))).log() # why -1 and why keepdim?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKYjaO6zYyjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = torch.randn(5,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y75enF2Y3FC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8d33cc41-e949-437f-ab38-c0bf4cfe05fe"
      },
      "source": [
        "test,test.sum(0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.4632,  2.3031,  0.5137, -0.1657,  0.2398,  0.1950,  0.2044, -0.2768,\n",
              "           1.3609,  1.4264],\n",
              "         [-1.3046, -1.1168,  0.4278,  0.8081, -1.7714, -0.2768,  1.8887,  0.9140,\n",
              "           0.5760,  2.1604],\n",
              "         [ 1.0079,  1.6093, -0.7888, -0.9303,  0.8233,  0.9852,  0.8579,  1.3346,\n",
              "           0.0589,  0.4880],\n",
              "         [-0.7185, -1.1339, -1.0247,  0.1673,  0.1162, -0.0271,  0.2119, -0.3768,\n",
              "          -1.3323,  0.3518],\n",
              "         [ 0.8657,  0.9302, -0.4037, -1.9461,  0.9511, -1.0854, -1.2676,  1.1612,\n",
              "           0.9190, -0.8615]]),\n",
              " tensor([ 1.3137,  2.5920, -1.2758, -2.0667,  0.3590, -0.2090,  1.8953,  2.7562,\n",
              "          1.5824,  3.5652]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AobgzTLdY-Qs",
        "colab_type": "code",
        "outputId": "8d0572b6-2212-41dc-fbf8-bda0889681b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "test.sum(0,keepdim = True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3137,  2.5920, -1.2758, -2.0667,  0.3590, -0.2090,  1.8953,  2.7562,\n",
              "          1.5824,  3.5652]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfly2gXIZRpL",
        "colab_type": "code",
        "outputId": "1357e175-2a8d-4b69-9063-72e2a06db68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "test.sum(-1),test.sum(-1,keepdim = True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 7.2640,  2.3054,  5.4460, -3.7661, -0.7370]), tensor([[ 7.2640],\n",
              "         [ 2.3054],\n",
              "         [ 5.4460],\n",
              "         [-3.7661],\n",
              "         [-0.7370]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-1AN6OkZYBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sm_pred = log_softmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6fvB1ufZv_v",
        "colab_type": "text"
      },
      "source": [
        "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
        "\n",
        "$$ -\\sum x\\, \\log p(x) $$\n",
        "But since our $x$s are 1-hot encoded, this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target.\n",
        "\n",
        "This can be done using numpy-style integer array indexing. Note that PyTorch supports all the tricks in the advanced indexing methods discussed in that link."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWJaMXa_ZvOn",
        "colab_type": "code",
        "outputId": "b39aaaa2-1aed-4b88-d016-03e36944bf2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[:3]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqvEfPLmsblP",
        "colab_type": "code",
        "outputId": "48f61f81-825c-484c-b123-149829d96d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sm_pred.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9TE4nlBwEDR",
        "colab_type": "text"
      },
      "source": [
        "Indexing ways"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTCCbuIBvkZy",
        "colab_type": "code",
        "outputId": "339ec019-ca70-4e6c-a837-6d545392b3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "sm_pred[[1,2,3]]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.4921, -2.5271, -2.4226, -2.3120, -2.2209, -2.1862, -2.2951, -2.2243,\n",
              "         -2.2264, -2.1896],\n",
              "        [-2.2550, -2.4051, -2.4227, -2.2969, -2.2616, -2.2413, -2.3434, -2.2324,\n",
              "         -2.2519, -2.3366],\n",
              "        [-2.2766, -2.4187, -2.4219, -2.3266, -2.3210, -2.1780, -2.3072, -2.2929,\n",
              "         -2.2661, -2.2417]], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sN11oTRxPyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAkqKTqTwBZR",
        "colab_type": "code",
        "outputId": "5445983c-b694-4ba0-e2c6-8ce2bcf9b00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sm_pred[[0,1,2],[5, 0, 4]]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.1938, -2.4921, -2.2616], grad_fn=<IndexBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwRBkuNzwOp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]),target].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpCLAT_JUtOS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = nll(sm_pred, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdgJnTOAxFQl",
        "colab_type": "code",
        "outputId": "a0fb8fe5-b408-46db-a5d6-7ee0fbc4f9fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3196, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPa0OkoVyBhZ",
        "colab_type": "text"
      },
      "source": [
        "Note that the formula\n",
        "\n",
        "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$\n",
        "gives a simplification when we compute the log softmax, which was previously defined as (x.exp()/(x.exp().sum(-1,keepdim=True))).log()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "737QMBWCx8qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1,keepdim=True).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR5DjTD1yIWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4lUz7SayuVe",
        "colab_type": "text"
      },
      "source": [
        "Then, there is a way to compute the log of the sum of exponentials in a more stable way, called the LogSumExp trick. The idea is to use the following formula:\n",
        "\n",
        "$$\\log \\left ( \\sum_{j=1}^{n} e^{x_{j}} \\right ) = \\log \\left ( e^{a} \\sum_{j=1}^{n} e^{x_{j}-a} \\right ) = a + \\log \\left ( \\sum_{j=1}^{n} e^{x_{j}-a} \\right )$$\n",
        "where a is the maximum of the $x_{j}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFWWFnrsyLZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logsumexp(x):\n",
        "    m = x.max(-1)[0]\n",
        "    return m + (x-m[:,None]).exp().sum(-1).log()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7OwMWv82iDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(logsumexp(pred), pred.logsumexp(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAL6uLft2nmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.logsumexp(-1,keepdim=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7VNvjG2t3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_near(nll(log_softmax(pred), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4SlrK3c2xcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyTorch's implementation.\n",
        "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM3utHEI22Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In PyTorch, F.log_softmax and F.nll_loss are combined in one optimized function, F.cross_entropy\n",
        "test_near(F.cross_entropy(pred, y_train), loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piDX1oHq3Eqk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Basic training loop\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "1.get the output of the model on a batch of inputs\n",
        "\n",
        "2.compare the output to the labels we have and compute a loss\n",
        "\n",
        "3.calculate the gradients of the loss with respect to every parameter of the model\n",
        "\n",
        "4.update said parameters with those gradients to make them a little bit better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lb0jpVha3CJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOoS8lu3zzb",
        "colab_type": "code",
        "outputId": "4e33925d-6b06-4481-86f3-8d61b8d2d333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "temp = tensor([[0,1,0],[1,0,0],[1,0,0]]).float()\n",
        "temp"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1BFUSnJ45kv",
        "colab_type": "code",
        "outputId": "75952aff-e4c3-4139-b046-e990d73f0b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.argmax(temp,dim=1),torch.argmax(temp,dim=0)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 0, 0]), tensor([2, 0, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMtbYr1o3X5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(out, yb): return (torch.argmax(out,dim=1)==yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my07FKMQ5C1-",
        "colab_type": "code",
        "outputId": "7bcec24d-5d53-4ec7-df6d-43c8a578d6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bs = 64\n",
        "\n",
        "xb = x_train[:bs]\n",
        "preds = model(xb)\n",
        "preds[0], preds.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.1153, -0.1818, -0.1031,  0.0138,  0.0827,  0.1002, -0.0749,  0.0296,\n",
              "          0.0748,  0.0458], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpAup36Q5lM0",
        "colab_type": "code",
        "outputId": "872f24a6-602e-4ed5-bb47-9f327ac77055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "yb = y_train[0:bs]\n",
        "loss_func(preds, yb)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3219, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMhIEx5B7QHw",
        "colab_type": "code",
        "outputId": "1aeaabbc-9d9b-4748-8433-f49033f7cfba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy(preds, yb)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0781)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4hZ9z0H7UcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.1 \n",
        "epochs = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAJURLbf7v4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = x_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHh6wWVOKHsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Linear??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R48uyBdh7htX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  for batch in range((n-1)//bs +1):\n",
        "    \n",
        "    x_batch = x_train[batch*bs:(batch+1)*bs]\n",
        "    y_batch = y_train[batch*bs:(batch+1)*bs]\n",
        "    \n",
        "    preds = model(x_batch)\n",
        "    \n",
        "    loss = loss_func(preds,y_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for l in model.layers:\n",
        "        if hasattr(l, 'weight'):\n",
        "          l.weight -= l.weight.grad*lr\n",
        "          l.bias -= l.bias.grad*lr\n",
        "          l.weight.grad.zero_()\n",
        "          l.bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umDCBQQZE-mC",
        "colab_type": "code",
        "outputId": "78d8aaf0-973e-44d3-a057-9569335d61aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2974, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duhixw1hUhFv",
        "colab_type": "text"
      },
      "source": [
        "Using parameters and optim\n",
        "\n",
        "Parameters\n",
        "\n",
        "Use nn.Module.__setattr__ and move relu to functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og9F3S4QFKgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        \n",
        "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyloIqjATJOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(m, nh, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl97hFDyUxVA",
        "colab_type": "code",
        "outputId": "00c091bf-3403-46e8-e77e-df0ada338682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "for name,l in model.named_children(): print(f\"{name}: {l}\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l1: Linear(in_features=784, out_features=50, bias=True)\n",
            "l2: Linear(in_features=50, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIMtNCl6U5fH",
        "colab_type": "code",
        "outputId": "fad10434-44c2-4518-c2d9-ff7b8ae9c52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcKKrtbWVKJ5",
        "colab_type": "code",
        "outputId": "9d64483f-8057-4d48-879a-d2e5ce6ef2b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.l1"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=50, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naiMuzMWVO3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for i in range((n-1)//bs + 1):\n",
        "            start_i = i*bs\n",
        "            end_i = start_i+bs\n",
        "            xb = x_train[start_i:end_i]\n",
        "            yb = y_train[start_i:end_i]\n",
        "            loss = loss_func(model(xb), yb)\n",
        "\n",
        "            loss.backward()\n",
        "            with torch.no_grad():\n",
        "                for p in model.parameters(): p -= p.grad * lr\n",
        "                model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD6TOHC6aHmQ",
        "colab_type": "code",
        "outputId": "84c8adb8-84c0-4d61-d9c9-3885b1b2a5ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3010, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ7WFG6laWRb",
        "colab_type": "text"
      },
      "source": [
        "Behind the scenes, PyTorch overrides the __setattr__ function in nn.Module so that the submodules you define are properly registered as parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84eenkEZaLSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyModule():\n",
        "    def __init__(self, n_in, nh, n_out):\n",
        "        self._modules = {}\n",
        "        self.l1 = nn.Linear(n_in,nh)\n",
        "        self.l2 = nn.Linear(nh,n_out)\n",
        "        self.n = 3\n",
        "        \n",
        "    def __setattr__(self,k,v):\n",
        "        if not k.startswith(\"_\") and hasattr(v,'parameters'): self._modules[k] = v\n",
        "        super().__setattr__(k,v)\n",
        "        \n",
        "    def __repr__(self): return f'{self._modules}'\n",
        "    \n",
        "    def parameters(self):\n",
        "        for l in self._modules.values():\n",
        "            for p in l.parameters(): yield p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mgsTewnaerl",
        "colab_type": "code",
        "outputId": "62b97a8d-4d44-4036-dd7a-514ab1b445f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "mdl = DummyModule(m,nh,10)\n",
        "mdl"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhXNJQCa4ZP",
        "colab_type": "code",
        "outputId": "8b1cc764-f136-4497-afe6-1290a7c1fdc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "[o.shape for o in mdl.parameters()]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([50, 784]),\n",
              " torch.Size([50]),\n",
              " torch.Size([10, 50]),\n",
              " torch.Size([10])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANDcit_NehxT",
        "colab_type": "text"
      },
      "source": [
        "**Registering modules**\n",
        "\n",
        "We can use the original layers approach, but we have to register the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0RSQvLFbAWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm_eV-wPcDHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS0ii6xJev8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ6UoWC1e0E2",
        "colab_type": "code",
        "outputId": "96368bd3-34c8-45a7-9b14-c7b4a0a7e485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (layer_1): ReLU()\n",
              "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8X3CbG7fIF-",
        "colab_type": "text"
      },
      "source": [
        "**nn.ModuleList**\n",
        "\n",
        "nn.ModuleList does this for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6t3-sVPe1tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequentialModel(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def __call__(self, x):\n",
        "        for l in self.layers: x = l(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHuXCPpifPdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SequentialModel(layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr6rWTfDfRP3",
        "colab_type": "code",
        "outputId": "17c94d9f-45d1-4ebd-c26b-12b55d3eeaeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequentialModel(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPPz2mhfS1B",
        "colab_type": "code",
        "outputId": "ec276771-f0f4-4ac7-a105-48376f92584a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3107, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v8HuspGflrO",
        "colab_type": "text"
      },
      "source": [
        "**nn.Sequential**\n",
        "\n",
        "nn.Sequential is a convenient class which does the same as the above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPUdXgKSfVXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpUMMEbhiOdS",
        "colab_type": "code",
        "outputId": "0373d032-80c4-43a4-e383-604d6c6f44fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2996, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md3eV2aLiQbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sequential??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va-5gxUziS1W",
        "colab_type": "code",
        "outputId": "d621bba8-8213-4b71-eb2c-7a09f159265e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CYQSFwtilCU",
        "colab_type": "text"
      },
      "source": [
        "**optim**\n",
        "\n",
        "Let's replace our previous manually coded optimization step\n",
        ":\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()\n",
        "```\n",
        "\n",
        "\n",
        "    \n",
        "and instead use just:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "opt.step()\n",
        "opt.zero_grad()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyZR68_MijxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Optimizer():\n",
        "  \n",
        "  def __init__(self, params, lr=0.5): self.params,self.lr=list(params),lr\n",
        "    \n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      for p in self.params: p -= p.grad*lr\n",
        "        \n",
        "  def zero_grad(self):\n",
        "    for p in self.params: p.grad.data.zero_()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL6OeNsgjjKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGivvEhHjmCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Optimizer(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkrOfewsjoIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir4O1DSilD7_",
        "colab_type": "code",
        "outputId": "e143afbf-c1d2-4956-9fa9-fcdf92b8ab9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1584, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "andZAjaHlM72",
        "colab_type": "text"
      },
      "source": [
        "PyTorch already provides this exact functionality in optim.SGD (it also handles stuff like momentum, which we'll look at later - except we'll be doing it in a more flexible way!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmH_-L2JlGv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiIAbOh5lV0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim.SGD.step??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CziWLb_XlYlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB1cYFDKrSr2",
        "colab_type": "code",
        "outputId": "8a73ea4a-f2fb-464e-8621-720d6bb2bc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "loss_func(model(xb), yb)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3162, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYdlUxFrVdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        start_i = i*bs\n",
        "        end_i = start_i+bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iskbinMercoi",
        "colab_type": "code",
        "outputId": "c2d7aa26-2b6c-4219-df16-898dd56ccf5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "loss,acc"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1527, grad_fn=<NllLossBackward>), tensor(0.9375))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F715hr6frfnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-9d-jZarj-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class Dataset():\n",
        "    def __init__(self, x, y): self.x,self.y = x,y\n",
        "    def __len__(self): return len(self.x)\n",
        "    def __getitem__(self,i): return self.x[i],self.y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyB_uDJPr4uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds = Dataset(x_train,y_train), Dataset(x_valid,y_valid)\n",
        "assert len(train_ds)==len(x_train)\n",
        "assert len(valid_ds)==len(x_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEUtkF7ssIx",
        "colab_type": "code",
        "outputId": "a397369c-f642-459b-ee49-9aad2559f9f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "xb,yb = train_ds[0:5]\n",
        "assert xb.shape==(5,28*28)\n",
        "assert yb.shape==(5,)\n",
        "xb,yb"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGTjmeMSs8CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Y3QdeEs_wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    for i in range((n-1)//bs + 1):\n",
        "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B52JG0ktUD7",
        "colab_type": "code",
        "outputId": "c4b0c150-939d-4138-934c-70181258f6ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.1483, grad_fn=<NllLossBackward>), tensor(1.))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKhA_HrmucNv",
        "colab_type": "text"
      },
      "source": [
        "**DataLoader**\n",
        "\n",
        "Previously, our loop iterated over batches (xb, yb) like this:\n",
        "\n",
        "\n",
        "```\n",
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    ...\n",
        "```\n",
        "Let's make our loop much cleaner, using a data loader:\n",
        "\n",
        "\n",
        "```\n",
        "for xb,yb in train_dl:\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdYmexnutZmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "  def __init__(self, ds, bs): self.ds, self.bs = ds,bs\n",
        "  def __iter__(self):\n",
        "    for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs] # note here yield is used"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBgkn9YfvzD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs)\n",
        "valid_dl = DataLoader(valid_ds, bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TRdEiM4v-pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "assert xb.shape==(bs,28*28)\n",
        "assert yb.shape==(bs,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY47_Y_hwA-4",
        "colab_type": "code",
        "outputId": "4351e52c-e4f0-4aea-e8e0-00edc344c472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWxGsrprwMH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model,opt = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1wXWEfpwqPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for xb,yb in train_dl:\n",
        "            pred = model(xb)\n",
        "            loss = loss_func(pred, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOwm0y4Gwr_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjH_wVquws8A",
        "colab_type": "code",
        "outputId": "8e3c10de-0923-4c10-9ac5-c1351d2872f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2727, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31zJUfXZyi5D",
        "colab_type": "text"
      },
      "source": [
        "**Random sampling**\n",
        "\n",
        "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP5fyO3SwwzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sampler():\n",
        "    def __init__(self, ds, bs, shuffle=False):\n",
        "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
        "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNdGn3CxyOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "small_ds = Dataset(*train_ds[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43n3gwrixz-W",
        "colab_type": "code",
        "outputId": "e3cf5fc2-9207-4bd3-a049-1c3e337210a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = Sampler(small_ds,3,False)\n",
        "[o for o in s]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fv-VikxyIxo",
        "colab_type": "code",
        "outputId": "f7d5129a-514b-4f5f-8d3a-8f876f3371ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s = Sampler(small_ds,3,True)\n",
        "[o for o in s]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([4, 3, 7]), tensor([5, 1, 9]), tensor([2, 8, 0]), tensor([6])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nd-5nLDyO2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate(b):\n",
        "    xs,ys = zip(*b)\n",
        "    return torch.stack(xs),torch.stack(ys)\n",
        "  \n",
        "class DataLoader():\n",
        "    def __init__(self, ds, sampler, collate_fn=collate):\n",
        "        self.ds,self.sampler,self.collate_fn = ds,sampler,collate_fn\n",
        "        \n",
        "    def __iter__(self):\n",
        "        for s in self.sampler: yield self.collate_fn([self.ds[i] for i in s])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvvU2YpHyW3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
        "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMhmI-1WygbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, sampler=train_samp, collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, sampler=valid_samp, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLiaH4cy22a",
        "colab_type": "code",
        "outputId": "5e5d66b0-5d2b-499a-cbcf-97bc08a8c39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(valid_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXGStUmRfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EnONtBI3kvX",
        "colab_type": "code",
        "outputId": "6e3bbbc5-a3a3-48d5-9543-50806d2b5533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V7654P23nm9",
        "colab_type": "code",
        "outputId": "ea3ce0d0-7ffd-4388-a673-313a103ed71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "xb,yb = next(iter(train_dl))\n",
        "plt.imshow(xb[0].view(28,28))\n",
        "yb[0]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aBdLj6z3szx",
        "colab_type": "code",
        "outputId": "529607d5-68c0-4e65-856e-45729ba46a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.3596, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQgDoLiQ4Nui",
        "colab_type": "text"
      },
      "source": [
        "**PyTorch DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l_Js-wW3xRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMwt9YbJ4Tnh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
        "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLGaqYjH4X72",
        "colab_type": "code",
        "outputId": "762bb342-9119-4d76-968c-7eca4d7ef5fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "loss_func(model(xb), yb), accuracy(model(xb), yb)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4400, grad_fn=<NllLossBackward>), tensor(0.8750))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVmBiX7265SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DataLoader??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMJPWXTo4aGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
        "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6JYlHP_7cSH",
        "colab_type": "text"
      },
      "source": [
        "PyTorch's defaults work fine for most things however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXs-_RrB4d3v",
        "colab_type": "code",
        "outputId": "6a1e53fc-5a1b-470b-d749-e2018e1b6db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model,opt = get_model()\n",
        "fit()\n",
        "\n",
        "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
        "assert acc>0.7\n",
        "loss,acc"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.2827, grad_fn=<NllLossBackward>), tensor(0.9219))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0masRS8S7kRd",
        "colab_type": "text"
      },
      "source": [
        "Note that PyTorch's DataLoader, if you pass num_workers, will use multiple threads to call your Dataset.\n",
        "\n",
        "\n",
        "\n",
        "**Validation**\n",
        "\n",
        "You always should also have a validation set, in order to identify if you are overfitting.\n",
        "\n",
        "We will calculate and print the validation loss at the end of each epoch.\n",
        "\n",
        "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NY_fgiD7Gpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        # Handle batchnorm / dropout\n",
        "        model.train()\n",
        "#         print(model.training)\n",
        "        for xb,yb in train_dl:\n",
        "            loss = loss_func(model(xb), yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "        \n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "          # we calculate loss and accuracy on valid set which is displayed as metric after each epoch\n",
        "          tot_loss, tot_acc = 0.,0.\n",
        "          for xb, yb in valid_dl:  \n",
        "            pred = model(xb)\n",
        "            tot_loss += loss_func(pred, yb)\n",
        "            tot_acc += accuracy(pred,yb)\n",
        "        nv = len(valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "        \n",
        "    return tot_loss/nv, tot_acc/nv\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqcZwMYo-Yep",
        "colab_type": "text"
      },
      "source": [
        "Question: Are these validation results correct if batch size varies?\n",
        "\n",
        "get_dls returns dataloaders for the training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzjJu0sv8A_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8_KHoGn8EN1",
        "colab_type": "code",
        "outputId": "709d7f01-3819-4a40-c475-216ecbc560c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
        "model,opt = get_model()\n",
        "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.2880) tensor(0.9168)\n",
            "1 tensor(0.2096) tensor(0.9423)\n",
            "2 tensor(0.1788) tensor(0.9499)\n",
            "3 tensor(0.1634) tensor(0.9543)\n",
            "4 tensor(0.1370) tensor(0.9617)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1nRVOXU-vn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert acc>0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRwdYrYlViq5",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# DataBunch/Learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8WTIKYz-5oX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()\n",
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "nh,bs = 50,64\n",
        "c = y_train.max().item()+1\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1F5tRczVwZX",
        "colab_type": "text"
      },
      "source": [
        "Factor out the connected pieces of info out of the fit() argument list\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n",
        "\n",
        "Let's replace it with something that looks like this:\n",
        "\n",
        "fit(1, learn)\n",
        "\n",
        "This will allow us to tweak what's happening inside the training loop in other places of the code because the Learner object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4R5hLsmWspv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DataLoader??"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_fWuTUVvFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c=None):\n",
        "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
        "        \n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "        \n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abKX1ZSBYQbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIM65IbkYR8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def get_model(data, lr=0.5, nh=50):\n",
        "    m = data.train_ds.x.shape[1]\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXn7pmhzYgeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiltzxncZgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, learn):\n",
        "    for epoch in range(epochs):\n",
        "        learn.model.train()\n",
        "        for xb,yb in learn.data.train_dl:\n",
        "            loss = learn.loss_func(learn.model(xb), yb)\n",
        "            loss.backward()\n",
        "            learn.opt.step()\n",
        "            learn.opt.zero_grad()\n",
        "\n",
        "        learn.model.eval()\n",
        "        with torch.no_grad():\n",
        "            tot_loss,tot_acc = 0.,0.\n",
        "            for xb,yb in learn.data.valid_dl:\n",
        "                pred = learn.model(xb)\n",
        "                tot_loss += learn.loss_func(pred, yb)\n",
        "                tot_acc  += accuracy (pred,yb)\n",
        "        nv = len(learn.data.valid_dl)\n",
        "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
        "    return tot_loss/nv, tot_acc/nv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJwuEnF8ccwG",
        "colab_type": "code",
        "outputId": "6fb1cc28-58ba-463d-ad05-6df6121a3113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss,acc = fit(1, learn)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.1498) tensor(0.9566)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXZhYkpgcjXb",
        "colab_type": "text"
      },
      "source": [
        "# CallbackHandler\n",
        "\n",
        "This was our training loop (without validation) from the previous notebook, with the inner loop contents factored out:\n",
        "\n",
        "\n",
        "```\n",
        "def one_batch(xb,yb):\n",
        "    pred = model(xb)\n",
        "    loss = loss_func(pred, yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "\n",
        "def fit():\n",
        "    for epoch in range(epochs):\n",
        "        for b in train_dl: one_batch(*b)\n",
        "```\n",
        "\n",
        "Add callbacks so we can remove complexity from loop, and make it flexible:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8CLNBXkcgQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_batch(xb, yb, cb):\n",
        "    if not cb.begin_batch(xb,yb): return\n",
        "    loss = cb.learn.loss_func(cb.learn.model(xb), yb)\n",
        "    if not cb.after_loss(loss): return\n",
        "    loss.backward()\n",
        "    if cb.after_backward(): cb.learn.opt.step()\n",
        "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
        "\n",
        "def all_batches(dl, cb):\n",
        "    for xb,yb in dl:\n",
        "        one_batch(xb, yb, cb)\n",
        "        if cb.do_stop(): return\n",
        "\n",
        "def fit(epochs, learn, cb):\n",
        "    if not cb.begin_fit(learn): return\n",
        "    for epoch in range(epochs):\n",
        "        if not cb.begin_epoch(epoch): continue\n",
        "        all_batches(learn.data.train_dl, cb)\n",
        "        \n",
        "        if cb.begin_validate():\n",
        "            with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
        "        if cb.do_stop() or not cb.after_epoch(): break\n",
        "    cb.after_fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_G0coC2RqJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Callback():\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn = learn\n",
        "        return True\n",
        "    def after_fit(self): return True\n",
        "    def begin_epoch(self, epoch):\n",
        "        self.epoch=epoch\n",
        "        return True\n",
        "    def begin_validate(self): return True\n",
        "    def after_epoch(self): return True\n",
        "    def begin_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        return True\n",
        "    def after_loss(self, loss):\n",
        "        self.loss = loss\n",
        "        return True\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0bXK8PRssc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CallbackHandler():\n",
        "    def __init__(self,cbs=None):\n",
        "        self.cbs = cbs if cbs else []\n",
        "\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn,self.in_train = learn,True\n",
        "        learn.stop = False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
        "        return res\n",
        "\n",
        "    def after_fit(self):\n",
        "        res = not self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_fit()\n",
        "        return res\n",
        "    \n",
        "    def begin_epoch(self, epoch):\n",
        "        learn.model.train()\n",
        "        self.in_train=True\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
        "        return res\n",
        "\n",
        "    def begin_validate(self):\n",
        "        self.learn.model.eval()\n",
        "        self.in_train=False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_validate()\n",
        "        return res\n",
        "\n",
        "    def after_epoch(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_epoch()\n",
        "        return res\n",
        "      \n",
        "    def begin_batch(self, xb, yb):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
        "        return res\n",
        "\n",
        "    def after_loss(self, loss):\n",
        "        res = self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
        "        return res\n",
        "\n",
        "    def after_backward(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_backward()\n",
        "        return res\n",
        "\n",
        "    def after_step(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_step()\n",
        "        return res\n",
        "    \n",
        "    def do_stop(self):\n",
        "        try:     return learn.stop\n",
        "        finally: learn.stop = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "px5OhzCiVqiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "    def begin_fit(self,learn):\n",
        "        super().begin_fit(learn)\n",
        "        self.n_iters = 0\n",
        "        return True\n",
        "        \n",
        "    def after_step(self):\n",
        "        self.n_iters += 1\n",
        "        print(self.n_iters)\n",
        "        if self.n_iters>=10: learn.stop = True\n",
        "        return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M245fnahV7A0",
        "colab_type": "code",
        "outputId": "4cae7775-436f-4e2c-ffb7-c907e45466e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "fit(1, learn, cb=CallbackHandler([TestCallback()]))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5PVlCIgWJ7w",
        "colab_type": "text"
      },
      "source": [
        "This is roughly how fastai does it now (except that the handler can also change and return xb, yb, and loss). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing cb to so many functions is a strong hint they should all be in the same class!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVQt47poyTOH",
        "colab_type": "text"
      },
      "source": [
        "# Runner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuqmMMBkZ1mK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "import re\n",
        "\n",
        "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
        "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
        "\n",
        "def camel2snake(name):\n",
        "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
        "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
        "  \n",
        "class Callback():\n",
        "    _order=0\n",
        "    def set_runner(self, run): self.run = run\n",
        "    def __getattr__(self, k): return getattr(self.run, k)\n",
        "    \n",
        "    @property \n",
        "    def name(self):\n",
        "      name = re.sub(r'Callback$','', self.__class__.__name__)\n",
        "      return camel2snake(name or 'callback')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42WVi-y9Z4IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TrainEvalCallback(Callback):\n",
        "  def begin_fit(self):\n",
        "    self.run.n_epochs = 0.\n",
        "    self.run.n_iter = 0\n",
        "    \n",
        "  def after_batch(self):\n",
        "    if not self.in_train: return\n",
        "    self.run.n_epochs += 1./self.iters\n",
        "    self.run.n_iter += 1\n",
        "    \n",
        "  def begin_epoch(self):\n",
        "    self.run.n_epochs = self.epoch\n",
        "    self.model.train()\n",
        "    self.run.in_train = True\n",
        "    \n",
        "  def begin_validate(self):\n",
        "    self.model.eval()\n",
        "    self.run.in_train=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY1F6HkV0CYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(Callback):\n",
        "  def after_step(self):\n",
        "    if self.train_eval.n_iters>=10: return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-5kWgFV301P",
        "colab_type": "code",
        "outputId": "5f51f359-1a0d-419c-f277-2d7c99222d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cbname = 'TrainEvalCallback'\n",
        "camel2snake(cbname)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval_callback'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IKg2A5j32wa",
        "colab_type": "code",
        "outputId": "1b3de131-8c6b-4f99-c6ed-0be43a1c9c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "TrainEvalCallback().name"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'train_eval'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ7-ej5D39Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from typing import *\n",
        "\n",
        "def listify(o):\n",
        "    if o is None: return []\n",
        "    if isinstance(o, list): return o\n",
        "    if isinstance(o, Iterable): return list(o)\n",
        "    return [o]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaAplbdB4hDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Runner():\n",
        "  def __init__(self, cbs = None, cb_funcs = None):\n",
        "    cbs = listify(cbs)\n",
        "    for cbf in listify(cb_funcs):\n",
        "      cb = cbf()\n",
        "      setattr(self, cb.name, cb)\n",
        "      cbs.append(cb)\n",
        "    self.stop, self.cbs = False, [TrainEvalCallback()]+cbs\n",
        "    \n",
        "  @property\n",
        "  def opt(self):       return self.learn.opt\n",
        "  \n",
        "  @property\n",
        "  def model(self):     return self.learn.model\n",
        "  \n",
        "  @property\n",
        "  def loss_func(self): return self.learn.loss_func\n",
        "  \n",
        "  @property\n",
        "  def data(self):      return self.learn.data\n",
        "  \n",
        "  \n",
        "  def one_batch(self, xb, yb):\n",
        "    self.xb,self.yb = xb,yb\n",
        "    if self('begin_batch'): return \n",
        "    self.pred = self.model(self.xb)\n",
        "    if self('after_pred'): return\n",
        "    self.loss = self.loss_func(self.pred,self.yb)\n",
        "    if self('after_loss') or not self.in_train: return\n",
        "    self.loss.backward()\n",
        "    if self('after_backward'): return \n",
        "    self.opt.step()\n",
        "    if self('after_step'): return\n",
        "    self.opt.step()\n",
        "    if self('after_step'): return\n",
        "    self.opt.zero_grad()\n",
        "    \n",
        "    \n",
        "  def all_batches(self, dl):\n",
        "    self.iters = len(dl)\n",
        "    for xb, yb in dl:\n",
        "      if self.stop: break\n",
        "      self.one_batch(xb, yb)\n",
        "      self('after_batch')\n",
        "    self.stop = False\n",
        "    \n",
        "  \n",
        "  def fit(self, epochs, learn):\n",
        "    self.epochs, self.learn = epochs, learn\n",
        "    \n",
        "    try:\n",
        "      for cb in self.cbs: cb.set_runner(self)\n",
        "      if self('begin_fit'): return\n",
        "      for epoch in range(epochs):\n",
        "        self.epoch = epoch\n",
        "        if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n",
        "          \n",
        "        with torch.no_grad():\n",
        "          if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n",
        "            \n",
        "        if self('after_epoch'): break\n",
        "          \n",
        "    finally:\n",
        "      self('after_fit')\n",
        "      self.learn = None\n",
        "      \n",
        "      \n",
        "  def __call__(self, cb_name):\n",
        "    for cb in sorted(self.cbs, key = lambda x: x._order):\n",
        "      f = getattr(cb, cb_name, None)\n",
        "      if f and f(): return True\n",
        "    return False\n",
        "      \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbSyuBxWq89D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class AvgStats():\n",
        "  def __init__(self, metrics, in_train): self.metrics, self.in_train = listify(metrics), in_train\n",
        "    \n",
        "  def reset(self):\n",
        "    self.tot_loss, self.count = 0., 0\n",
        "    self.tot_mets = [0.]*len(self.metrics)\n",
        "    \n",
        "  @property\n",
        "  def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
        "  \n",
        "  @property\n",
        "  def avg_stats(self): return [o/self.count for o in self.all_stats]\n",
        "  \n",
        "  def __repr__(self):\n",
        "    if not self.count: return \"\"\n",
        "    return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
        "  \n",
        "  def accumulate(self, run):\n",
        "    bn = run.xb.shape[0]\n",
        "    self.tot_loss += run.loss*bn\n",
        "    self.count += bn\n",
        "    for i,m in enumerate(self.metrics):\n",
        "      self.tot_mets[i] += m(run.pred, run.yb)*bn\n",
        "      \n",
        "\n",
        "class AvgStatsCallback(Callback):\n",
        "    def __init__(self, metrics):\n",
        "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
        "        \n",
        "    def begin_epoch(self):\n",
        "        self.train_stats.reset()\n",
        "        self.valid_stats.reset()\n",
        "        \n",
        "    def after_loss(self):\n",
        "        stats = self.train_stats if self.in_train else self.valid_stats\n",
        "        with torch.no_grad(): stats.accumulate(self.run)\n",
        "    \n",
        "    def after_epoch(self):\n",
        "        print(self.train_stats)\n",
        "        print(self.valid_stats)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inFaRVOkyFtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(*get_model(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvi0vNWHyMPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stats = AvgStatsCallback([accuracy])\n",
        "run = Runner(cbs = stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X1SBZpLyZO8",
        "colab_type": "code",
        "outputId": "9814a815-f974-47a1-c41f-c5114505cd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "run.fit(1, learn)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.3738536328125, tensor(0.8842)]\n",
            "valid: [0.2963546875, tensor(0.9114)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBe8zPi-zGhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWL8SkTMjLdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_learner(model_func, loss_func, data):\n",
        "    return Learner(*model_func(data), loss_func, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeCsZduvkKzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "bafcbe09-df38-4b32-819a-ccb5ecaa584e"
      },
      "source": [
        "learn = create_learner(get_model, loss_func, data)\n",
        "run = Runner([AvgStatsCallback([accuracy])])\n",
        "\n",
        "run.fit(3, learn)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.740076015625, tensor(0.7727)]\n",
            "valid: [0.91708056640625, tensor(0.8046)]\n",
            "train: [0.5824399609375, tensor(0.8347)]\n",
            "valid: [1.5895037109375, tensor(0.6235)]\n",
            "train: [0.442903359375, tensor(0.8800)]\n",
            "valid: [0.3518050048828125, tensor(0.9038)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6qF9o4CkMwh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "44bc1887-53d8-496b-c7cd-3977e0ba47a6"
      },
      "source": [
        "learn = create_learner(partial(get_model, lr=0.3), loss_func, data)\n",
        "run = Runner([AvgStatsCallback([accuracy])])\n",
        "\n",
        "run.fit(3, learn)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: [0.31816611328125, tensor(0.9017)]\n",
            "valid: [0.17946131591796874, tensor(0.9444)]\n",
            "train: [0.145839228515625, tensor(0.9564)]\n",
            "valid: [0.11700789794921874, tensor(0.9670)]\n",
            "train: [0.112160009765625, tensor(0.9666)]\n",
            "valid: [0.10814210205078124, tensor(0.9681)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHtH8pCFkT6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_func(lr=0.5): return partial(get_model, lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zShYuTEUmPZQ",
        "colab_type": "text"
      },
      "source": [
        "## Annealing\n",
        "We define two new callbacks: the Recorder to save track of the loss and our scheduled learning rate, and a ParamScheduler that can schedule any hyperparameter as long as it's registered in the state_dict of the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egv2AR-qlwN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Recorder(Callback):\n",
        "  def begin_fit(self): self.lrs, self.losses = [], []\n",
        "    \n",
        "  def after_batch(self):\n",
        "    if not self.in_train: return \n",
        "    self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
        "    self.losses.append(self.loss.detach().cpu())\n",
        "    \n",
        "  def plot_lr(self): plt.plot(self.lrs)\n",
        "  def plot_loss(self): plt.plot(self.losses)\n",
        "    \n",
        "class ParamSchheduler(Callback):\n",
        "  _order = 1\n",
        "  def __init__(self, pname, sched_func): self.pname, self.sched_func = pname, sched_func\n",
        "    \n",
        "  def set_param(self):\n",
        "    for pg in self.opt.param_groups:\n",
        "      pg[self.pname] = self.sched_func(self.n_epochs/self.epochs)\n",
        "      \n",
        "  def begin_batch(self):\n",
        "    if self.in_train: self.set_param()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbpOZ0bvpAyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sched_lin(start, end):\n",
        "    def _inner(start, end, pos): return start + pos*(end-start)\n",
        "    return partial(_inner, start, end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqEAlcrupClx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def annealer(f):\n",
        "    def _inner(start, end): return partial(f, start, end)\n",
        "    return _inner\n",
        "  \n",
        "@annealer\n",
        "def sched_lin(start, end, pos): return start + pos*(end-start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPrxHy3DARzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5fccef1-c1cf-49d6-eb3d-eda78e7c32ba"
      },
      "source": [
        "f = sched_lin(1,2)\n",
        "f(0.3)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-1ApICoAybn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#export\n",
        "@annealer\n",
        "def sched_cos(start, end, pos): return start + (1 + math.cos(math.pi*(1-pos))) * (end-start) / 2\n",
        "@annealer\n",
        "def sched_no(start, end, pos):  return start\n",
        "@annealer\n",
        "def sched_exp(start, end, pos): return start * (end/start) ** pos\n",
        "\n",
        "#This monkey-patch is there to be able to plot tensors\n",
        "torch.Tensor.ndim = property(lambda x: len(x.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYCwHOlwA4dZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1a3fc65f-bb6d-4f41-ff7f-e8f2b4b42c3f"
      },
      "source": [
        "annealings = \"NO LINEAR COS EXP\".split()\n",
        "\n",
        "a = torch.arange(0, 100)\n",
        "p = torch.linspace(0.01,1,100)\n",
        "\n",
        "fns = [sched_no, sched_lin, sched_cos, sched_exp]\n",
        "for fn, t in zip(fns, annealings):\n",
        "    f = fn(2, 1e-2)\n",
        "    plt.plot(a, [f(o) for o in p], label=t)\n",
        "plt.legend();"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By1VvS2yA7bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_scheds(pcts, scheds):\n",
        "    assert sum(pcts) == 1.\n",
        "    pcts = tensor([0] + listify(pcts))\n",
        "    assert torch.all(pcts >= 0)\n",
        "    pcts = torch.cumsum(pcts, 0)\n",
        "    def _inner(pos):\n",
        "        idx = (pos >= pcts).nonzero().max()\n",
        "        actual_pos = (pos-pcts[idx]) / (pcts[idx+1]-pcts[idx])\n",
        "        return scheds[idx](actual_pos)\n",
        "    return _inner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGno6aA3CTJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sched = combine_scheds([0.3, 0.7], [sched_cos(0.3, 0.6), sched_cos(0.6, 0.2)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc5En5Q8CYdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(a, [sched(o) for o in p])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9FeuDPOCaj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cbfs = [Recorder,\n",
        "        partial(AvgStatsCallback,accuracy),\n",
        "        partial(ParamScheduler, 'lr', sched)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTAfm3IrC-OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = create_learner(get_model_func(0.3), loss_func, data)\n",
        "run = Runner(cb_funcs=cbfs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NStwlbZ_DDkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run.fit(3, learn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jD40JOKDGMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run.recorder.plot_lr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tpk_9yODIW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run.recorder.plot_loss()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}